{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kgpark88/energy-bigdata-analysis/blob/main/spark_in_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w43TrZtZq_C4"
      },
      "source": [
        "#  Colab에서 PySpark 실행하는 방법\n",
        "- 참조 : https://medium.com/@TheITspace/running-pyspark-on-google-colab-2552435972b3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M4xT7qkpSrb",
        "outputId": "4ddcfd90-6c1b-4eb5-c925-b19bdb834ae4"
      },
      "source": [
        "# Colab에서 PySpark 사용하는 방법 1\n",
        "!pip install pyspark py4j"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.9/dist-packages (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317145 sha256=c89016cd77cdcb172b99d493df0bbbde3092c718eb1fd11e657c38c9dd7baf33\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/34/a4/159aa12d0a510d5ff7c8f0220abbea42e5d81ecf588c4fd884\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Colab에서 PySpark 사용하는 방법 2\n",
        "# !apt-get install openjdk-8-jdk-headless -qq \n",
        "# !wget -q !wget -q https://downloads.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz  \n",
        "# !tar -xf spark-3.3.2-bin-hadoop3.tgz\n",
        "# !pip install -q findspark\n",
        "\n",
        "# import os\n",
        "# import findspark\n",
        "\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\"\n",
        "\n",
        "# findspark.init()\n",
        "# findspark.find()"
      ],
      "metadata": {
        "id": "gvxaWK6oC7zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRdkpnOkr_-n"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"demo\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIfnIselsYnH"
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCRjuwBBs-EO"
      },
      "source": [
        "## ngrok를 사용하여 Spark UI 접속"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz"
      ],
      "metadata": {
        "id": "jCVzdOsmjcDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tEiX_8Lsi5Y"
      },
      "source": [
        "!tar xf ngrok-v3-stable-linux-amd64.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  !./ngrok authtoken <authtoken > # https://dashboard.ngrok.com/\n",
        "!./ngrok authtoken 68EgMVst4xkntqLofArnK_7VuGPawLqhayeXRFfNLtH"
      ],
      "metadata": {
        "id": "IG0zwVsqhvoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 4050 &')"
      ],
      "metadata": {
        "id": "lKuVPlG2x_sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps -ef | grep ngrok"
      ],
      "metadata": {
        "id": "L8P-sBy7x4HZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "\"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "metadata": {
        "id": "lwGSayC3liEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnFEnB0-tE2H"
      },
      "source": [
        "## 데이터 로딩\n",
        "- 데이터 출처 : https://www.kaggle.com/sdolezel/black-friday"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Sh8w4-stFld"
      },
      "source": [
        "df = spark.read.csv(\"train.csv\", header=True, inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV0mt-KFvVTO"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma4yZtIUvZUB"
      },
      "source": [
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYx0MlbxvbrO"
      },
      "source": [
        "df.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNtLYEZY0YFb"
      },
      "source": [
        "## PySpark 사용법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKFIX3Z2wDCF"
      },
      "source": [
        "### 특정 컬럼 데이터 보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x3jxCsgvetF"
      },
      "source": [
        "df.select(\"User_ID\",\"Gender\",\"Age\",\"Occupation\").show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYhSOc-JwIZO"
      },
      "source": [
        "### 컬럼"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOjfXzNLvh5G"
      },
      "source": [
        "df.describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWWTzjgswQo9"
      },
      "source": [
        "### 범주형 컬럼(Categorical columns)의 유일값 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OUqG4Fgv1e1"
      },
      "source": [
        "df.select(\"City_Category\").distinct().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQq2TqJVv99W"
      },
      "source": [
        "### Groupby 집계\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPdZ51Zqv6Q-"
      },
      "source": [
        "from pyspark.sql import functions as F\n",
        "df.groupBy(\"City_Category\").agg(F.sum(\"Purchase\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XivhGYj2xYXQ"
      },
      "source": [
        "### Null value 확인 및 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53a2MopNxZBZ"
      },
      "source": [
        "df.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in df.columns]).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMpyfrcaxkO1"
      },
      "source": [
        "df = df.fillna({'Product_Category_2':0, 'Product_Category_3':0})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Keo7HZhpxmuG"
      },
      "source": [
        "df.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in df.columns]).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baECVey4xrv8"
      },
      "source": [
        "## 데이터 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTISG3d7xsmX"
      },
      "source": [
        "df.write.csv(\"pre_processed_data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI9c5KVeyCq1"
      },
      "source": [
        "df.rdd.getNumPartitions()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD_y2nWqyilM"
      },
      "source": [
        "## Pandas 데이터프레임으로 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCFbr3mzyjWY"
      },
      "source": [
        "df_pd = df.toPandas()\n",
        "df_pd.to_csv(\"pandas_pre_processed_data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "abZ2tIuu6OYt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}