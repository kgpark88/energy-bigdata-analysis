{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark_in_colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kgpark88/energy-bigdata-analysis/blob/main/spark_in_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w43TrZtZq_C4"
      },
      "source": [
        "#  Colab에서 PySpark 사용하는 방법\n",
        "- 참조 : https://www.analyticsvidhya.com/blog/2020/11/a-must-read-guide-on-how-to-work-with-pyspark-on-google-colab-for-data-scientists/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tED_90krGWw"
      },
      "source": [
        "## Java Virtual Machine (JVM) 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M4xT7qkpSrb",
        "outputId": "4b2e4c66-3d67-4b77-b0a0-5c32aae75434"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "openjdk-8-jdk-headless is already the newest version (8u312-b07-0ubuntu1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA66MhL-rRP_"
      },
      "source": [
        "## Apache Spark 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlUyWRlFpjFh"
      },
      "source": [
        "!wget -q https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOKnx2cmptJA"
      },
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y1kL_vlqvkZ",
        "outputId": "ea5c99e3-719f-40d9-d809-13374ea8b3a7"
      },
      "source": [
        "!ls -lt"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 506184\n",
            "-rw-r--r--  1 root root  25525678 Apr 24 03:14 train.csv\n",
            "drwxr-xr-x  3 root root      4096 Apr 24 03:13 drive\n",
            "-rw-r--r--  1 root root  13832437 Apr 24 03:10 ngrok-stable-linux-amd64.zip\n",
            "drwxr-xr-x  1 root root      4096 Apr 19 14:23 sample_data\n",
            "-rw-r--r--  1 root root 224445805 May 24  2021 spark-3.1.2-bin-hadoop2.7.tgz\n",
            "-rw-r--r--  1 root root 224445805 May 24  2021 spark-3.1.2-bin-hadoop2.7.tgz.1\n",
            "drwxr-xr-x 13 1000 1000      4096 May 24  2021 spark-3.1.2-bin-hadoop2.7\n",
            "-rwxr-xr-x  1 root root  30053267 May  4  2021 ngrok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ2R5ha2rem3"
      },
      "source": [
        "##  findspark 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v9I6uADqwWz"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puRVH9hTrmIe"
      },
      "source": [
        "## 환경변수 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpIKzokFrnzP"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wSapyZ_r2on"
      },
      "source": [
        "## 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLM4fjnur1OB"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6zsO9LvHr6mX",
        "outputId": "02d70c4a-1a4b-42db-f9b6-52e97efde66f"
      },
      "source": [
        "findspark.find()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.1.2-bin-hadoop2.7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRdkpnOkr_-n"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "LIfnIselsYnH",
        "outputId": "22c94eee-680b-4052-85ff-8fb9a5565922"
      },
      "source": [
        "spark"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fcd7d043090>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://3648db09a176:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCRjuwBBs-EO"
      },
      "source": [
        "## Spark UI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tEiX_8Lsi5Y",
        "outputId": "3235f03c-0113-4a67-96aa-9c8b6f63c385"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-24 03:17:31--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.202.168.65, 54.161.241.46, 18.205.222.128, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.202.168.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  18.1MB/s    in 0.7s    \n",
            "\n",
            "2022-04-24 03:17:32 (18.1 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7iipEEEsyzf"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!curl -s http://localhost:4040/api/tunnels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnFEnB0-tE2H"
      },
      "source": [
        "## 데이터 로딩\n",
        "- 데이터 : https://www.kaggle.com/sdolezel/black-friday"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Sh8w4-stFld"
      },
      "source": [
        "df = spark.read.csv(\"train.csv\", header=True, inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV0mt-KFvVTO"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma4yZtIUvZUB"
      },
      "source": [
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYx0MlbxvbrO"
      },
      "source": [
        "df.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNtLYEZY0YFb"
      },
      "source": [
        "## PySpark 사용법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKFIX3Z2wDCF"
      },
      "source": [
        "### 특정 컬럼 데이터 보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x3jxCsgvetF"
      },
      "source": [
        "df.select(\"User_ID\",\"Gender\",\"Age\",\"Occupation\").show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYhSOc-JwIZO"
      },
      "source": [
        "### 컬럼"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOjfXzNLvh5G"
      },
      "source": [
        "df.describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWWTzjgswQo9"
      },
      "source": [
        "### 범주형 컬럼(Categorical columns)의 유일값 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OUqG4Fgv1e1"
      },
      "source": [
        "df.select(\"City_Category\").distinct().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQq2TqJVv99W"
      },
      "source": [
        "### Groupby 집계\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPdZ51Zqv6Q-"
      },
      "source": [
        "from pyspark.sql import functions as F\n",
        "df.groupBy(\"City_Category\").agg(F.sum(\"Purchase\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XivhGYj2xYXQ"
      },
      "source": [
        "### Null value 확인 및 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53a2MopNxZBZ"
      },
      "source": [
        "df.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in df.columns]).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMpyfrcaxkO1"
      },
      "source": [
        "df = df.fillna({'Product_Category_2':0, 'Product_Category_3':0})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Keo7HZhpxmuG"
      },
      "source": [
        "df.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in df.columns]).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baECVey4xrv8"
      },
      "source": [
        "## 데이터 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTISG3d7xsmX"
      },
      "source": [
        "df.write.csv(\"/content/drive/MyDrive/preprocessed_data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI9c5KVeyCq1"
      },
      "source": [
        "df.rdd.getNumPartitions()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD_y2nWqyilM"
      },
      "source": [
        "## Pandas 데이터프레임으로 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCFbr3mzyjWY"
      },
      "source": [
        "df_pd = df.toPandas()\n",
        "df_pd.to_csv(\"/content/drive/MyDrive/pandas_preprocessed_data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oxH14S6aj5Ij"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}